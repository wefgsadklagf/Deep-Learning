{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Keras-入门---笑脸识别\" data-toc-modified-id=\"Keras-入门---笑脸识别-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Keras 入门 - 笑脸识别</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras 入门 - 笑脸识别\n",
    "\n",
    "本文是基于keras 的函数式模型进行编写的神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "import kt_utils \n",
    "import keras \n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 600\n",
      "number of test examples = 150\n",
      "X_train shape: (600, 64, 64, 3)\n",
      "Y_train shape: (600, 1)\n",
      "X_test shape: (150, 64, 64, 3)\n",
      "Y_test shape: (150, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = kt_utils.load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Reshape\n",
    "Y_train = Y_train_orig.T\n",
    "Y_test = Y_test_orig.T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape):\n",
    "    #定义一个tensor的placeholder，维度为input_shape\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    #使用0填充：X_input的周围填充0\n",
    "    X = ZeroPadding2D((3,3))(X_input)\n",
    "    \n",
    "    # 对X使用 CONV -> BN -> RELU 块\n",
    "    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #最大值池化层\n",
    "    X = MaxPooling2D((2,2),name=\"max_pool\")(X)\n",
    "    \n",
    "    #降维，矩阵转化为向量 + 全连接层\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "    \n",
    "    #创建模型，讲话创建一个模型的实体，我们可以用它来训练、测试。\n",
    "    model = Model(inputs = X_input, outputs = X, name='HappyModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HappyModel(input_shape):\n",
    "    \"\"\"\n",
    "    实现一个检测笑容的模型\n",
    "    \n",
    "    参数：\n",
    "        input_shape - 输入的数据的维度\n",
    "    返回：\n",
    "        model - 创建的Keras的模型\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    #你可以参考和上面的大纲\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    #使用0填充：X_input的周围填充0\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    #对X使用 CONV -> BN -> RELU 块\n",
    "    X = Conv2D(32, (7, 7), strides=(1, 1), name='conv0')(X)\n",
    "    X = BatchNormalization(axis=3, name='bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    #最大值池化层\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "\n",
    "    #降维，矩阵转化为向量 + 全连接层\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "\n",
    "    #创建模型，讲话创建一个模型的实体，我们可以用它来训练、测试。\n",
    "    model = Model(inputs=X_input, outputs=X, name='HappyModel')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "600/600 [==============================] - 20s 33ms/step - loss: 3.8774 - acc: 0.4950\n",
      "Epoch 2/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.8310 - acc: 0.7100\n",
      "Epoch 3/40\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.4064 - acc: 0.8300\n",
      "Epoch 4/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.2085 - acc: 0.9033\n",
      "Epoch 5/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.1499 - acc: 0.9450\n",
      "Epoch 6/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.1225 - acc: 0.9583\n",
      "Epoch 7/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.1049 - acc: 0.9700\n",
      "Epoch 8/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0901 - acc: 0.9750\n",
      "Epoch 9/40\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0818 - acc: 0.9800\n",
      "Epoch 10/40\n",
      "600/600 [==============================] - 17s 29ms/step - loss: 0.0780 - acc: 0.9767\n",
      "Epoch 11/40\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0697 - acc: 0.9767\n",
      "Epoch 12/40\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0798 - acc: 0.9717\n",
      "Epoch 13/40\n",
      "600/600 [==============================] - 18s 29ms/step - loss: 0.0617 - acc: 0.9867\n",
      "Epoch 14/40\n",
      "600/600 [==============================] - 19s 31ms/step - loss: 0.0545 - acc: 0.9833\n",
      "Epoch 15/40\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0578 - acc: 0.9867\n",
      "Epoch 16/40\n",
      "600/600 [==============================] - 19s 32ms/step - loss: 0.0517 - acc: 0.9883\n",
      "Epoch 17/40\n",
      "600/600 [==============================] - 18s 31ms/step - loss: 0.0491 - acc: 0.9883\n",
      "Epoch 18/40\n",
      "600/600 [==============================] - 18s 30ms/step - loss: 0.0468 - acc: 0.9900\n",
      "Epoch 19/40\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0484 - acc: 0.9867\n",
      "Epoch 20/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0442 - acc: 0.9900\n",
      "Epoch 21/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0440 - acc: 0.9867\n",
      "Epoch 22/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0338 - acc: 0.9900\n",
      "Epoch 23/40\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0497 - acc: 0.9850\n",
      "Epoch 24/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0481 - acc: 0.9867\n",
      "Epoch 25/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0316 - acc: 0.9933\n",
      "Epoch 26/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0364 - acc: 0.9900\n",
      "Epoch 27/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0360 - acc: 0.9883\n",
      "Epoch 28/40\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0283 - acc: 0.9950\n",
      "Epoch 29/40\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0221 - acc: 0.9933\n",
      "Epoch 30/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0196 - acc: 0.9950\n",
      "Epoch 31/40\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0181 - acc: 0.9983\n",
      "Epoch 32/40\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0316 - acc: 0.9900\n",
      "Epoch 33/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0215 - acc: 0.9967\n",
      "Epoch 34/40\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0343 - acc: 0.9883\n",
      "Epoch 35/40\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.0199 - acc: 0.9950\n",
      "Epoch 36/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0177 - acc: 0.9933\n",
      "Epoch 37/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 38/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0148 - acc: 0.9950\n",
      "Epoch 39/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0129 - acc: 0.9983\n",
      "Epoch 40/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.0224 - acc: 0.9917\n",
      "150/150 [==============================] - 2s 12ms/step\n",
      "误差值 = 0.10694946686426798\n",
      "准确度 = 0.9533333373069763\n"
     ]
    }
   ],
   "source": [
    "#创建一个模型实体\n",
    "happy_model = HappyModel(X_train.shape[1:])\n",
    "#编译模型\n",
    "happy_model.compile(\"adam\",\"binary_crossentropy\", metrics=['accuracy'])\n",
    "#训练模型\n",
    "#请注意，此操作会花费你大约6-10分钟。\n",
    "happy_model.fit(X_train, Y_train, epochs=40, batch_size=50)\n",
    "#评估模型\n",
    "preds = happy_model.evaluate(X_test, Y_test, batch_size=32, verbose=1, sample_weight=None)\n",
    "print (\"误差值 = \" + str(preds[0]))\n",
    "print (\"准确度 = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#写一个LossHistory类，保存loss和acc\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch':[], 'epoch':[]}\n",
    "        self.accuracy = {'batch':[], 'epoch':[]}\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('acc'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('acc'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure()\n",
    "        # acc\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "        # loss\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#创建一个实例history\n",
    "history = LossHistory()\n",
    "\n",
    "#绘制acc-loss曲线\n",
    "history.loss_plot('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:tf1]",
   "language": "python",
   "name": "conda-env-tf1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
